\subsection{Parallelism vs overhead}
A task-based runtime need to dispatch tasks all over the available computational cores.
%
But this action isn't completely free, some operations need to be done by the scheduler and depends on its implementation.
%
Generally more the runtime is complex, more it will spend time to dispatch tasks.
%
A very simple runtime could be composed of a shared queue, in which tasks are inserted when a core can execute them.
%
This queue must be thread safe since every thread will enqueue/dequeue tasks at the same time.
%
Unfortunately, even this type of runtime have an overhead when it enqueue/dequeue a task.
%
This overhead can be negligible if the time spend in the task is much higher than the overhead.
%
But with a fine-grain parallelism, this overhead is far to be considerate as negligible and the programmer needs to deal with it.
%
Even a static scheduler has overhead, since all tasks are distributed over all cores, the scheduler needs to check if all dependencies of the task are satisfied.
%
This could be do more or less efficiently but in all case we lost the dynamic load balancing aspect of a dynamic scheduler.


Increasing the grain size of tasks in a program is a solution, but it could also reduce the possibilities of parallelism and load balancing provide by the runtime.
%
Parallelism and load balancing are linked, runtime need to have enough parallelism to achieve a good load balancing.
%
So, most of the time, finding the perfect grain size is painful.
%
If the grain size is too big, the runtime cannot fairly balance the computation over all cores of the processor.
%
But on the contrary, if the grain size is too small, the overhead of the runtime kills performances.


Several related works have been conducted in the past to address the issue of adapting the task grain size to the amount of available computing units.
%
Many related works partially address this grain size issue by promoting cache-oblivious techniques for a specific class of
applications such as recursive, divide-and-conquer codes or recursively partitioned loops~\cite{unifieddataflow,Intel::TBB,Cilk,xkaapi,taskscomparison}.
%
Works such as the SCOOPP framework~\cite{scoopp} provides means for the applications to control the task grain size.
%
However, the grain size selection issue is still up to the application programmer.


On the theoretical side, general task scheduling has been heavily studied for a long time now~\cite{Khan94acomparison,heft}.
%
Works on task grain adaptiveness have been scarcer, but do exist.
