\subsection{Passage de messages}
Certaines machines ne fonctionnent pas avec une mémoire globale, chaque noeud de calcul à une mémoire locale et il ne peut pas accéder directement à la mémoire des autres noeuds distants, ces machines sont dites à mémoire distribuée.
%
Avec le paradigme de passage de messages, chaque processus a son propre espace mémoire virtuel et communique avec les autres processus par le biais d'envoi/réception de messages.
%
Ces communications se font à l'aide d'une interface de programmation qui fournit des fonctions permettant l'échange de messages point-à-point.
%
L'interface la plus connue et la plus utilisée actuellement est MPI\footnote{Message Passing Interface}.
%
Elle permet de faire communiquer deux processus ensemble sans se soucier du réseau utilisé ou même de la différence d'endianness entre deux architectures différentes.


L'un des avantages majeur de ce paradigme est qu'il permet d'utiliser un ensemble très varié de machine.
%
Il fonctionne aussi en mémoire partagée qu'en mémoire distribuée.
%
Par contre, certains algorithmes ne peuvent pas être écrits efficacement avec ce paradigme.
%
Dans notre cas, la factorisation d'une matrice creuse se parallélise très mal.
%
Nous sommes obligés de modifier de méthodes de factorisation pour être capable d'obtenir de la performance.
