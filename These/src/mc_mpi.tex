\subsection{Passage de messages}
Certaines machines ne fonctionnent pas avec une mémoire globale, mais avec une mémoire distribuée.
% 
Chaque noeud de calcul a une mémoire locale et ne peut pas accéder directement à la mémoire des autres noeuds distants.
%
Avec le paradigme de passage de messages, chaque processus a son propre espace mémoire virtuel et communique avec les autres processus par le biais d'envoi/réception de messages.
%
Ces communications se font à l'aide d'une interface de programmation qui fournit des fonctions permettant l'échange de messages point-à-point.
%
L'interface la plus connue et la plus utilisée actuellement est MPI\footnote{Message Passing Interface}.
%
Elle permet de faire communiquer deux processus ensemble sans se soucier du réseau utilisé ni même de la différence d'encodage des entiers ({\em little endian}/{\em big endian}) entre deux architectures différentes.

L'un des avantages majeurs de ce paradigme est qu'il permet d'utiliser un ensemble très varié de machines.
%
Il fonctionne aussi bien en mémoire partagée qu'en mémoire distribuée.
%
Son utilisation en mémoire partagée permet de n'utiliser qu'un seul type de parallélisme dans un programme.
%
Un programme pur MPI peut donc utiliser tous les coeurs d'un noeud de calcul avec le même code source qui permet d'utiliser des grappes de serveurs.
%
Mais il ne s'agit pas toujours de l'implémentation la plus efficace pour paralléliser un code, il est souvent plus performant d'utiliser une parallélisation hybride MPI+Threads\cite{mpi_openmp}.
%
De plus, certains algorithmes ne peuvent pas être écrits efficacement avec ce paradigme.
%
Par exemple, dans notre cas la factorisation d'une matrice creuse se parallélise très mal en mémoire distribuée.
%
Nous ne pouvons extraire du parallélisme qu'entre les factorisations de ligne de la matrice.
%
Or ce niveau de granularité du calcul ne donne pas de bonnes performances avec un paradigme par passage de messages.
%
Nous sommes donc obligés de modifier les méthodes de factorisation pour être capables d'obtenir de la performance.
%
La méthode de Jacobi par blocs permet d'effectuer en parallèle une factorisation sur chaque bloc au détriment de la convergence de la méthode itérative.
%
C'est donc cette méthode qui est utilisée pour une parallélisation par passage de messages.
%
Cette méthode a l'inconvénient d'ignorer de nombreuses connexions entre les cellules du réservoir et fournit donc un préconditionnement de moins bonne qualité qu'une factorisation ILU sur la matrice complète.
