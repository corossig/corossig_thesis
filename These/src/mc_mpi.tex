\subsection{Passage de messages}
Certaines machines ne fonctionnent pas avec une mémoire globale, chaque noeud de calcul a une mémoire locale et il ne peut pas accéder directement à la mémoire des autres noeuds distants, ces machines sont dites à mémoire distribuée.
%
Avec le paradigme de passage de messages, chaque processus a son propre espace mémoire virtuel et communique avec les autres processus par le biais d'envoi/réception de messages.
%
Ces communications se font à l'aide d'une interface de programmation qui fournit des fonctions permettant l'échange de messages point-à-point.
%
L'interface la plus connue et la plus utilisée actuellement est MPI\footnote{Message Passing Interface}.
%
Elle permet de faire communiquer deux processus ensemble sans se soucier du réseau utilisé ou même de la différence d'endianness entre deux architectures différentes.


L'un des avantages majeur de ce paradigme est qu'il permet d'utiliser un ensemble très varié de machine.
%
Il fonctionne aussi en mémoire partagée qu'en mémoire distribuée.
%
Son utilisation en mémoire partagée permet de n'utiliser qu'un seul type de parallélisme dans un programme.
%
Un programme pure MPI peut donc utiliser tous les coeurs d'un noeud de calcul avec le même code source qui permet d'utiliser des grappes de serveurs.
%
Mais il ne s'agit pas toujours de l'implémentation la plus efficace pour paralléliser un code, il est souvent plus performant d'utiliser une parallélisation hybride MPI+Threads\cite{mpi_openmp}.
%
De plus, certains algorithmes ne peuvent pas être écrits efficacement avec ce paradigme.
%
Par exemple, dans notre cas la factorisation d'une matrice creuse se parallélise très mal.
%
Nous ne pouvons pas extraire du parallélisme qu'entre les factorisations des lignes de la matrices.
%
Or ce niveau de granularité du calcul ne donne pas de bonnes performances avec un paradigme par passage de messages.
%
Nous sommes donc obligés de modifier les méthodes de factorisation pour être capable d'obtenir de la performance.
%
La décomposition en sous-domaines des cellules du réservoir permet d'effectuer en parallèle une factorisation sur chaque domaine.
%
C'est donc cette méthode qui est utilisée pour une parallélisation par passage de messages.
%
Cette méthode a l'inconvénient d'ignorer de nombreuses connexions entre les cellules du réservoir fournis donc un résultat de moins bonne qualité qu'une méthode sans décomposition de domaine.
