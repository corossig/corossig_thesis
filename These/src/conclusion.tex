\section{Conclusion}
%La simulation de réservoir permet aux compagnies pétrolières d'optimiser le placement des puits lors de l'exploitation d'un champ pétrolier.
%
%La résolution des systèmes d'équations linéaires creux peut représenter jusqu'à 80\% du temps de simulation.
%
La parallélisation des méthodes de résolution de grands systèmes linéaires creux est cruciale pour réduire les temps de calcul de nombreuses applications scientifiques.
%
En particulier en simulation de réservoir, cette étape consomme plus de 80\% du temps de calcul.
%
Dans cette thèse, nous avons proposé des bibliothèques de parallélisation à grain fin pour les algorithmes élémentaires d'algèbre linéaire creuse qui sont utilisés dans les méthodes de résolution itératives.
%
Notre but était de proposer un cadre de programmation qui étend le modèle de programmation proposé par Intel TBB ou OpenMP à des algorithmes où le coût de calcul d'une tâche est faible et où la bande passante limite la performance.
%
Nous avons proposé une approche transparente pour le développeur qui permet de prendre en compte des phénomènes complexes tels que la granularité des tâches où le placement des pages mémoires.
%
Pour évaluer notre approche, nous nous sommes concentrés sur les algorithmes qui sont représentatifs des méthodes itératives.
%
Ainsi, nous nous sommes donc concentrés à améliorer cette partie en commençant par la factorisation ILU, un des préconditionneurs du GMRES.
%
La parallélisation de la factorisation ILU(k) s'exprime facilement sous la forme d'un graphe de tâches, mais la granularité des tâches ne permet pas d'obtenir de bonnes performances.
%
La plupart des ordonnanceurs actuels mettent plus de temps à ordonnancer une tâche que la tâche ne met à exécuter son code.
%
Pour pouvoir modifier facilement cette granularité, nous avons élaboré un nouveau cadriciel que nous avons appelé Taggre.
%
Ce cadriciel prend en entrée un graphe de tâches à grain très fin et utilise des algorithmes pour grossir le grain de tâche en créant des groupes de tâches.
%
Pour cela, il utilise des opérateurs d'agrégations que nous avons définies dans le chapitre 2.
%
Chaque opérateur aura un objectif particulier d'optimisation du graphe.
%
En combinant ces opérateurs, nous pouvons obtenir un nouveau graphe à grain grossier.
%
Ce graphe pourra être ensuite utilisé par un ordonnanceur de tâches.
%
Taggre a permis d'obtenir une parallélisation MPI+Threads efficace du GMRES préconditionné par une factorisation ILU(0) permettant ainsi de diminuer le nombre de processus MPI utilisé.
%
Cette diminution a un impact à la fois sur la convergence de la méthode itérative ainsi que sur d'autres algorithmes pouvant eux aussi utiliser une parallélisation hybride pour obtenir de meilleurs performances.



Cette méthode d'agrégation de tâches est générique.
%
Dans le cadre de cette thèse, nous l'avons appliqué à la factorisation ILU(k) ainsi qu'aux résolutions triangulaires associées.
%
Nous l'avons aussi expérimenté sur des graphes un peu plus généraux grâce à un simulateur d'exécution de tâches.
%
Mais cette méthode pourrait aussi s'appliquer à d'autres noyaux d'algèbre linéaire creuse ainsi qu'à d'autres genres de problèmes représentant le parallélisme sous la forme d'un graphe de tâche.



Nous nous sommes ensuite concentrés sur l'optimisation des accès mémoire.
%
L'architecture de type NUMA des machines que nous utilisons nous a conduits à créer un nouvel ordonnanceur de tâche prenant en compte la localité mémoire des tâches de calcul.
%
Nos algorithmes étant limités par la bande passante mémoire, l'amélioration de la localité mémoire a conduit à une amélioration directe des performances.
%
Malheureusement, cet ordonnanceur a été développé avec pour objectif de fonctionner sur des machines avec 2 bancs NUMA.
%
L'utilisation d'une machine ayant plus de bancs NUMA a montrée les limites de cet ordonnanceur.
%
Malgré ces limites, les résultats obtenus restent meilleurs que ceux obtenus avec un ordonnanceur classique.
%
Les résultats de ces travaux ont été présentés au workshop PDSEC de la conférence IPDPS2013.


Durant cette thèse, nous avons aussi eu l'occasion d'essayer notre code de calcul sur un coprocesseur Intel Xeon Phi.
%
La bande passante mémoire de ces coprocesseurs étant plus élevée que celle des processeurs que nous utilisons, nous avons obtenu de très bonnes performances sur les principaux noyaux de calculs du code.
%
Par contre, l'utilisation du mode natif pour la partie séquentielle du code contrebalance les gains obtenus.
