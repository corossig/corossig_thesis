\section{Perspectives}
Taggre sera utilisé pour paralléliser efficacement de nouvelles routines d'algèbre linaire creuse qui seront utilisé dans le simulateur de réservoir.
%
L'ordonnanceur de tâches que nous avons écrit peut aussi être amélioré.
%
Il n'a qu'une seule fonctionnalité, la gestion de l'affinité NUMA.
%
Des stratégies d'ordonnancement plus intelligentes pourraient être implémentées pour améliorer ces performances.
%
De plus, les structures de données actuelles ne permettent pas de l'utiliser efficacement sur plus de 3 bancs NUMA.


Les architectures actuelles tendent à avoir de plus en plus de coeurs de calcul par processeur.
%
Le Xeon Phi nous offre une vision de ces futurs processeurs et des moyens de programmation à notre disposition.
%
Malheureusement la version actuelle ne propose pas de bonnes performances séquentielles.
%
La prochaine version aura une exécution dans le désordre (out-of-order) et une meilleure fréquence d'horloge qui devrait résoudre le problème des parties de code séquentielles.


Capsules permet d'utiliser une parallélisation par graphe de tâches en définissant plusieurs grain de cacul.
%
Il pourrait être intéressant de coupler Taggre à Capsules.
%
Taggre s'occupera de définir plusieurs granularités avec une nouvelle granularité après chaque application d'un opérateur.
%
Capsules pourra ensuite utiliser ces différentes granularités pour ordonnancer efficacement le graphe de tâches.


Les opérateurs d'agrégations ont été créés pour résoudre les problèmes rencontrés en simulation de réservoir.
%
Le choix des opérateurs se fait à l'appréciation du programmeur.
%
Ce choix dépendra essentiellement de la forme du graphe de tâches ainsi que des propriétés des tâches.
%
Parmi ces propriétés, la granularité des tâches est importante,
%
Si la granularité des tâches est vraiment trop fine, il faudra privilégier des opérateurs qui créent de gros groupes de tâches.
%
Par contre pour une granularité moins fine, nous pouvons utiliser des opérateurs qui favorisent les interactions entre les tâches.
%
Nous proposons deux solutions pour rendre ce choix automatique avec chacun des avantages et des défauts.


La première solution est {\em l'auto-tuning}, elle consiste à parcourir l'espace des possibilités d'agrégations et à choisir la meilleure.
%
Le principal problème vient de la taille de l'espace à parcourir.
%
Pour réduire cette taille, nous pouvons utiliser des techniques d'optimisation pour éviter de tester des cas trop absurdes.
%
Nous pouvons aussi utiliser le simulateur d'exécution des tâches pour avoir une approximation du temps de calcul.
%
Mais cette approximation n'est pas aussi fiable qu'une vraie exécution car nous ne prenons pas en compte tous les paramètres.


La deuxième solution consiste à faire une analyse statique des tâches ainsi que du graphe de tâches.
%
Cette analyse est très complexe à mettre en oeuvre et les critères d'évaluation des graphes sont à définir.
%
Par contre, une fois tout le travail d'analyse effectué, le choix des opérateurs est rapide.


Le problème de définition de la fonction de tri de l'opérateur généralisé se pose toujours.
%
Deux solutions peuvent être développées :
\begin{itemize}
  \item la création de greffons pour Taggre permettant d'écrire du code C++ et de l'intégrer directement;
  \item la création d'un langage permettant de décrire les tâches qui sera interprété à l'exécution.
\end{itemize}
%
La première méthode a l'avantage d'être simple à mettre en oeuvre mais elle peut être difficile à utiliser.
%
La deuxième méthode est plus complète mais elle a l'inconvénient de demander beaucoup de travail au niveau de l'implémentation.


