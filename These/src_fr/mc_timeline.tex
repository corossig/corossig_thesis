\subsection{Timeline of runtime}
Back in 80's, some scientist succeed in interconnecting some processors together and obtain a parallel machine,
%
A new idea appears to make scheduler more flexible, it's name is {\em work-stealing}.
%
With this idea, tasks can be schedule during run-time, when a hardware resource is free.
%
One of the best example is Cilk~\cite{Cilk}, first published in 1994 and still developed under the Cilk++~\cite{Cilk++}.
%
Tasks are describe by the programmer with additional keywords to the C language, for example in Cilk the keyword {\em spawn} before a function call means that a task must be create and the runtime can schedule it.
%
In the case of Cilk a specific compiler must be use in order to transform the code into a set runtime call, this is close of source-to-source compiler.
%
The parallelism that consist in spawning tasks and then wait for some of them is often called {\em insert task} paradigm.
%
One can also used the name {\em sequential task graph} because the task graph is build along the computation.
%
On the opposite, one can found {\em Parametrized Task Graph} or in a shorter way {\em PTG} where the graph is a contraction of sequential task graph with conditions on edges.


OpenMP~\cite{OpenMP} is a different from above, it is a runtime specialized in loop parallelism without data dependency.
%
Somewhat like Cilk, it uses some language extension ({\em \#pragma omp action} in C) and a specific compiler must be used to translate the code (transform the loop into a function and call the right runtime functions).
%
In 1997, the specification 3.0 of OpenMP add the keyword {\em task} to support {\em sequential task graph}, it still doesn't support implicit data dependencies.
%
More recently, the specification 4.0 add an support of implicit data dependencies.
%
To date, OpenMP is certainly the most commonly used runtime through that one can obtain a parallel application with the simple well know line {\em \#pragma omp parallel for}


At begin of 2000's, architecture in the processor became parallel.
%
Two or more cores cohabit on a single chip and share some resources like cache or memory bandwidth.
%
One can have multi threading parallelism, but there is need of runtime to exploit this parallelism.
%
For example, Intel TBB (\textit{Threading Building Blocks})~\cite{Intel::TBB} which is developed by Intel since 2006 especially for abstract multi-core programming and with the same goal SMPSs~\cite{SMPSs}(now part of STARSs, see below) since 2007.

When we use a cluster, there is two choice.
%
On the one hand, there is DSM\footnote{Distributed Shared Memory}, which is very simple to use but
%
On the other hand, there is message passing paradigm, which is more difficult to use but give good result.
%
It is the most used paradigm for distributed memory especially with the MPI norm.
%

More recently, in the late 2000's, the GPGPU revolution leads the apparition of new type of runtime.
%
These runtimes must now support heterogeneous resources with sometimes several address spaces.
%
They must also integrate a support to automatically transfer data between the several address space.
%
Among these runtimes, one can found StarPU~\cite{starpu}, PaRSEC~\cite{PaRSEC}, X-KAAPI~\cite{xkaapi} and STARSs (became OMPSs~\cite{OMPSs} by the merge of SMPSs, ClusterSs and CellSs,\dots).

Some runtime specialized in loop parallelism also gain a GPU support, like OpenMP in is specification 4.0.
%
But this specification is mostly inspired from OpenACC~\cite{OpenACC} which wants to simplify parallel programming of heterogeneous CPU/GPU systems.
