%+++++++++++++++++++++++++++++++
\section{Current NUMA management}
In a general way, a program allocates memory from a virtual address space split into pages.
%
Each pages used by the program is transparently mapped by the Operating System to a physical memory location.
%
Thus, some virtual pages can also be moved from one physical location to another one, while the virtual/physical mapping is transparently updated accordingly to the Operating System without affecting the execution of user level programs.
%
However, the physical location of virtual page may impact the program performance on NUMA architectures, depending on the connectivity between the physical memory bank where a page is located and the socket core that is accessing this memory bank.
%
The NUMA memory allocation policy is defined by the kernel of the Operating System.
%
With Linux, at least the following three memory policies are generally available:
\begin{itemize}
        \item {\em First Touch}: Memory is allocated on the bank next to the core which accessed the data first.
                         This is the default policy.
        \item {\em Bind}: Memory is allocated on a specific bank.
        \item {\em Interleaved}: Memory allocations are interleaved among all the banks available.
\end{itemize}
On Linux, these policies can be set either through the \textit{mbind} system call, or with the {\em numactl} command line tool.
%
A new mechanism also come with the version 3.13 of Linux, AutoNUMA.
%
This mechanism use page fault trapping which has a non negligible overhead.
%
AutoNUMA can only be configured at system level with root privilege and for all applications.


Other operating system may come with their own specific sets of NUMA memory allocation policies.
%
Solaris, for instance, also provides the \textit{next-touch}~\cite{next_touch} policy.
%
When this policy is selected, a memory page is moved to the bank close to the core that subsequently accesses it.


%-------------------------------
\subsection{First touch}
This is the default policy on Linux.
%
When a thread wants to access to a not yet mapped virtual memory page, the kernel allocate a new physical page near to the thread.
%
The idea behind this policy isn't bad, a memory page is often use by one thread.
%
So when a thread touch a page for the first time, it may continue to work with this page and this page must be close to the thread.
%
But some threaded program doesn't work in that way.
%
Let's imagine the case that in a program the setup phase which allocate all pages isn't multithreaded.
%
In that case, all pages are allocated on the same NUMA node, close to the thread which have done the setup.


%-------------------------------
\subsection{Interleaved memory}
When the interleaved policy is selected, the kernel uniformly distributes newly allocated physical pages among all available NUMA banks, following a round robin scheme.
%
While having very little impact on the applicative code, the interleave policy often shows some effectiveness in mitigating NUMA overheads in the general case.
%
In average, the latency doesn't change too much but thease because of pages Because it distributes the required memory bandwidth over the various memory banks.
%
Thus, it is usually worthwhile to experiment with it, before investigating the NUMA issue further.


While the results we obtain show an improved speed-up with TBB and interleaved policy,
it should be noted that sequential runs with interleaved policy are of
course worse, because of memory access penalties introduced by NUMA.
%% Parallel runs however show a better speed-up.
When comparing
interleaved page allocation with first-touch allocation, we get
an average improvement of 3.5\,\% on ILU(k) preconditioner
and 6.2\,\% on triangular solve with two 4-core sockets.

These improvements could be further enhanced by taking into account the locality of data
used by tasks within the task scheduler. This is the purpose of the
following section.



%-------------------------------
\subsection{Next-touch}
%-------------------------------
\subsection{Automatic solution}
%-------------------------------
\subsection{One MPI per NUMA bank}
%+++++++++++++++++++++++++++++++
